{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ImageClassification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldIeJVbBmbQl"
      },
      "source": [
        "The CIFAR-10 dataset that we are using is available directly through the keras module. Therefore, it is easy to download and preprocess. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrLn_258lsbR"
      },
      "source": [
        "# Importing the dataset and other relevant modules\n",
        "from keras.datasets import cifar10\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.constraints import maxnorm\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJcHwpjXmh2Z"
      },
      "source": [
        "Below, we create our input (X) and output () matrices for training our neural networks. The keras module already provides separate training and test datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_soLxMblyfi",
        "outputId": "16c7881e-e848-45e0-8447-e67559c85852"
      },
      "source": [
        "# loading the data\n",
        "(train_X, train_Y), (test_X, test_Y) = cifar10.load_data()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n",
            "170508288/170498071 [==============================] - 2s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiFTK8P1mk1h"
      },
      "source": [
        "Now that we have our data, we need to preprocess it. Specifically, we need to convert the pixel values of the images to floats and then normalize the dataset by dividing by the highest pixel value (255)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwHjA4dDl4US"
      },
      "source": [
        "train_X = train_X.astype('float32')\n",
        "test_X = test_X.astype('float32')\n",
        " \n",
        "train_X = train_X/255.0\n",
        "test_X = test_X/255.0"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SR9EeJDgmnor"
      },
      "source": [
        "Finally, we need to convert our output to categorical variables for us to classify. We do this through one-hot encoding. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6J51stnl6Fg"
      },
      "source": [
        "train_Y = np_utils.to_categorical(train_Y)\n",
        "test_Y = np_utils.to_categorical(test_Y)\n",
        "\n",
        "num_classes=test_Y.shape[1]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZzuqLWHUwmO"
      },
      "source": [
        "We now define our model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WETxUN-uLiDL"
      },
      "source": [
        "model=Sequential()\n",
        "model.add(Conv2D(32,(3,3),input_shape=(32,32,3),padding='same',activation='relu',kernel_constraint=maxnorm(3)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv2D(32,(3,3),activation='relu',padding='same',kernel_constraint=maxnorm(3)))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512,activation='relu',kernel_constraint=maxnorm(3)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='relu'))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3uY-adRU5kP"
      },
      "source": [
        "We create an EarlyStopping function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwPdOjtkNfwz"
      },
      "source": [
        "es = EarlyStopping(monitor='val_loss', patience=20)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yJSVliWVI8R"
      },
      "source": [
        "Compiling the model and defining the loss function and the optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7acj81glNSIF"
      },
      "source": [
        "model.compile(loss='mean_squared_error', optimizer=\"adam\")"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0X5btoExVOCP"
      },
      "source": [
        "We can now take a look at the summary of our model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9sovcpZiNU37",
        "outputId": "da6d5ede-c7c6-4508-b290-5ab6200db0e4"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 16, 16, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 8192)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               4194816   \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,210,090\n",
            "Trainable params: 4,210,090\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N78aJFz_VVKQ"
      },
      "source": [
        "Finally, we fit the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exuU3TZkNZCM",
        "outputId": "914db15e-d16b-49bd-971d-acbee5965ee8"
      },
      "source": [
        "model.fit(train_X, train_Y, validation_data=(test_X, test_Y), epochs=10000000000000, callbacks=[es], batch_size=64, shuffle=True)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10000000000000\n",
            "782/782 [==============================] - 13s 15ms/step - loss: 5003.2466 - val_loss: 0.4212\n",
            "Epoch 2/10000000000000\n",
            "782/782 [==============================] - 12s 15ms/step - loss: 2.1693 - val_loss: 0.1040\n",
            "Epoch 3/10000000000000\n",
            "782/782 [==============================] - 12s 15ms/step - loss: 0.2033 - val_loss: 0.0993\n",
            "Epoch 4/10000000000000\n",
            "782/782 [==============================] - 12s 15ms/step - loss: 0.1225 - val_loss: 0.0982\n",
            "Epoch 5/10000000000000\n",
            "782/782 [==============================] - 12s 15ms/step - loss: 0.1749 - val_loss: 0.0968\n",
            "Epoch 6/10000000000000\n",
            "782/782 [==============================] - 12s 16ms/step - loss: 0.0960 - val_loss: 0.0952\n",
            "Epoch 7/10000000000000\n",
            "782/782 [==============================] - 12s 15ms/step - loss: 0.0945 - val_loss: 0.0936\n",
            "Epoch 8/10000000000000\n",
            "782/782 [==============================] - 12s 16ms/step - loss: 0.0930 - val_loss: 0.0923\n",
            "Epoch 9/10000000000000\n",
            "782/782 [==============================] - 12s 15ms/step - loss: 0.0919 - val_loss: 0.0915\n",
            "Epoch 10/10000000000000\n",
            "782/782 [==============================] - 12s 15ms/step - loss: 0.0913 - val_loss: 0.0911\n",
            "Epoch 11/10000000000000\n",
            "782/782 [==============================] - 12s 15ms/step - loss: 0.0911 - val_loss: 0.0910\n",
            "Epoch 12/10000000000000\n",
            "782/782 [==============================] - 12s 16ms/step - loss: 0.0910 - val_loss: 0.0910\n",
            "Epoch 13/10000000000000\n",
            "782/782 [==============================] - 12s 16ms/step - loss: 0.0910 - val_loss: 0.0910\n",
            "Epoch 14/10000000000000\n",
            "782/782 [==============================] - 12s 15ms/step - loss: 0.0910 - val_loss: 0.0910\n",
            "Epoch 15/10000000000000\n",
            "782/782 [==============================] - 12s 16ms/step - loss: 0.0910 - val_loss: 0.0910\n",
            "Epoch 16/10000000000000\n",
            "782/782 [==============================] - 12s 15ms/step - loss: 0.0910 - val_loss: 0.0910\n",
            "Epoch 17/10000000000000\n",
            "782/782 [==============================] - 12s 15ms/step - loss: 0.0910 - val_loss: 0.0910\n",
            "Epoch 18/10000000000000\n",
            "782/782 [==============================] - 12s 15ms/step - loss: 0.0910 - val_loss: 0.0910\n",
            "Epoch 19/10000000000000\n",
            "782/782 [==============================] - 12s 15ms/step - loss: 0.0910 - val_loss: 0.0910\n",
            "Epoch 20/10000000000000\n",
            "782/782 [==============================] - 12s 16ms/step - loss: 0.0910 - val_loss: 0.0910\n",
            "Epoch 21/10000000000000\n",
            "782/782 [==============================] - 12s 15ms/step - loss: 0.0910 - val_loss: 0.0910\n",
            "Epoch 22/10000000000000\n",
            "782/782 [==============================] - 12s 15ms/step - loss: 0.0910 - val_loss: 0.0910\n",
            "Epoch 23/10000000000000\n",
            "782/782 [==============================] - 12s 15ms/step - loss: 0.0910 - val_loss: 0.0910\n",
            "Epoch 24/10000000000000\n",
            "782/782 [==============================] - 12s 15ms/step - loss: 0.0910 - val_loss: 0.0910\n",
            "Epoch 25/10000000000000\n",
            "782/782 [==============================] - 12s 15ms/step - loss: 0.0910 - val_loss: 0.0910\n",
            "Epoch 26/10000000000000\n",
            "782/782 [==============================] - 12s 15ms/step - loss: 0.0910 - val_loss: 0.0910\n",
            "Epoch 27/10000000000000\n",
            "782/782 [==============================] - 12s 15ms/step - loss: 0.0910 - val_loss: 0.0910\n",
            "Epoch 28/10000000000000\n",
            "782/782 [==============================] - 12s 15ms/step - loss: 0.0910 - val_loss: 0.0910\n",
            "Epoch 29/10000000000000\n",
            "782/782 [==============================] - 12s 15ms/step - loss: 0.0910 - val_loss: 0.0910\n",
            "Epoch 30/10000000000000\n",
            "782/782 [==============================] - 12s 15ms/step - loss: 0.0910 - val_loss: 0.0910\n",
            "Epoch 31/10000000000000\n",
            "782/782 [==============================] - 12s 15ms/step - loss: 0.0910 - val_loss: 0.0910\n",
            "Epoch 32/10000000000000\n",
            "782/782 [==============================] - 12s 15ms/step - loss: 0.0910 - val_loss: 0.0910\n",
            "Epoch 33/10000000000000\n",
            "782/782 [==============================] - 12s 15ms/step - loss: 0.0910 - val_loss: 0.0910\n",
            "Epoch 34/10000000000000\n",
            "782/782 [==============================] - 12s 15ms/step - loss: 0.0910 - val_loss: 0.0910\n",
            "Epoch 35/10000000000000\n",
            "782/782 [==============================] - 12s 15ms/step - loss: 0.0910 - val_loss: 0.0910\n",
            "Epoch 36/10000000000000\n",
            "782/782 [==============================] - 12s 15ms/step - loss: 0.0910 - val_loss: 0.0910\n",
            "Epoch 37/10000000000000\n",
            "782/782 [==============================] - 12s 15ms/step - loss: 0.0911 - val_loss: 0.0910\n",
            "Epoch 38/10000000000000\n",
            "782/782 [==============================] - 12s 15ms/step - loss: 0.1064 - val_loss: 0.0911\n",
            "Epoch 39/10000000000000\n",
            "782/782 [==============================] - 12s 15ms/step - loss: 0.1112 - val_loss: 0.0910\n",
            "Epoch 40/10000000000000\n",
            "782/782 [==============================] - 12s 15ms/step - loss: 0.0910 - val_loss: 0.0910\n",
            "Epoch 41/10000000000000\n",
            "782/782 [==============================] - 12s 15ms/step - loss: 0.0910 - val_loss: 0.0910\n",
            "Epoch 42/10000000000000\n",
            "782/782 [==============================] - 12s 15ms/step - loss: 0.0910 - val_loss: 0.0910\n",
            "Epoch 43/10000000000000\n",
            "782/782 [==============================] - 12s 15ms/step - loss: 0.0910 - val_loss: 0.0910\n",
            "Epoch 44/10000000000000\n",
            "782/782 [==============================] - 12s 15ms/step - loss: 0.0910 - val_loss: 0.0910\n",
            "Epoch 45/10000000000000\n",
            "782/782 [==============================] - 12s 15ms/step - loss: 0.0910 - val_loss: 0.0910\n",
            "Epoch 46/10000000000000\n",
            "782/782 [==============================] - 12s 15ms/step - loss: 0.0910 - val_loss: 0.0910\n",
            "Epoch 47/10000000000000\n",
            "782/782 [==============================] - 12s 15ms/step - loss: 0.0910 - val_loss: 0.0910\n",
            "Epoch 48/10000000000000\n",
            "782/782 [==============================] - 12s 15ms/step - loss: 0.0910 - val_loss: 0.0910\n",
            "Epoch 49/10000000000000\n",
            "782/782 [==============================] - 12s 15ms/step - loss: 0.0910 - val_loss: 0.0910\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4ca7526a90>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZkZV65DVZL7"
      },
      "source": [
        "Evaluation of our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZauJLazN6cm",
        "outputId": "04a1c5c8-00bf-497d-e799-d8a979e4e709"
      },
      "source": [
        "model.evaluate(test_X,test_Y)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0910\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0910063311457634"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    }
  ]
}